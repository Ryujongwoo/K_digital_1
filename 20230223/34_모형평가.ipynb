{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525ec97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1026e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8f009",
   "metadata": {},
   "source": [
    "모형 평가\n",
    "\n",
    "오버피팅(overfitting)과 언더피팅(underfitting)  \n",
    "오버피팅은 특정 데이터셋에 과도하게 적합된 것을 의미한다. 오버피팅이 발생하는 경우, 얼핏 정확도가 높아 보이지만 특정 데이터셋에만 적합되어 <u>알려지지 않은 데이터에 대한 예측력은 낮아</u>지게 된다. 언더피팅은 데이터셋에 적합이 잘되지 않은, 즉 과소적합된 것을 의미한다.\n",
    "\n",
    "머신러닝을 통해 모형을 학습하는 이유는 데이터의 종류와 상관없이 일반화할 수 있는 모형을 생성하는 것이다. 주어진 데이터셋에 대해 오버피팅이나 언더피팅이 발생한다면 새로운 데이터에 적용할 수 있는 좋은 모형이라고 말하기 어렵다.\n",
    "\n",
    "오버피팅된 모형을 새로운 데이터셋에 적용한다면 학습 데이터셋과는 큰 오차를 보인다. 반대로 언더피팅은 트레이닝 데이터 셋과 테스트 데이터셋 모두 큰 오차를 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c0dd3",
   "metadata": {},
   "source": [
    "편향-분산 트레이드오프(bias-variance tradeoff)  \n",
    "편향 분산 트레이드오프란, <u>편향이 낮을수록 분산은 커지고, 반대로 편향이 높을수록 분산이 작아지는 경향</u>이 있다는 것을 의미한다.\n",
    "\n",
    "분산이 높은 현상은 주로 복잡한 모형에 나타나고 모형이 복잡하다는 말은 오버피팅이 발생할 가능성이 높다는 뜻이다. 즉, 복잡한 모형일수록 오버피팅이 발생할 가능성이 높으며, 이는 분산이 커진다는 것을 의미한다.  \n",
    "반대로 편향이 큰 현상은 주로 간단한 모형일 때 나타나는데 모형이 간단하다는 말은 언더피팅이 발생할 가능성이 높다는 뜻이다. 간단한 모형일수록 언더피팅이 발생할 가능성이 높으며, 이에 따라 편향이 커질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79045c5",
   "metadata": {},
   "source": [
    "크로스 벨리데이션(cross validation, 교차 검증)  \n",
    "모형을 생성한 후 실제 데이터에 적용해 보고 성능을 평가해야 하는데, 데이터셋 전체를 학습에 사용하면 새롭게 적용할 데이터가 없어서 문제가 발생되기 때문에 전체 데이터를 트레이닝 데이터와 테스트 데이터로 분할해서 사용한다. 트레이닝 데이터는 학습하는 데 사용되고, 테스트 데이터는 학습 시에는 사용되지 않고 모형의 성능을 평가할 때 사용한다.\n",
    "\n",
    "머신러닝 알고리즘을 적용할 때 다양한 하이퍼파라미터에 대해 여러 가지 모형 후보군을 생성하고 평가한 수 최종 모형을 선택하게 된다. 이때, 파라미터는 모형 내부에서 데이터에 의해 추정되는 값이고, 하이퍼파라미터는 사용자가 직접 정하는 값이다.\n",
    "\n",
    "하이퍼파라미터를 결정하는 과정에서 트레이닝 데이터와 테스트 데이터만 존재한다면 테스트 데이터에 의해 최종 모형의 파라미터가 결정된다. 즉, 모형의 하이퍼파라미터가 테스트 데이터에 의존한다는 뜻이다.\n",
    "\n",
    "이 문제를 해결하기 위해 트레이닝 데이터의 일부를 밸리데이션 데이터로 사용한다. 즉, 트레이닝 데이터는 파라미터를 구하는데 사용하고, 베리데이션 데이터는 하이퍼파라미터를 정하는데 사용한다.\n",
    "\n",
    "주어진 데이터셋에 대해서 트레이닝 데이터, 밸리데이션 데이터, 테스트 데이터로 분할할 수 있는 다양한 조합 방법이 존재한다. 이처럼 다양한 조합을 통해 모형의 성능을 검증하는 것을 크로스-밸리데이션이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4eba3",
   "metadata": {},
   "source": [
    "파이프라인  \n",
    "파이썬을 활용한 머신러닝 실습 과정에서 파이프라인을 사용하면 데이터 전처리와 학습 모형을 연결해 코드를 간겨화 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b643cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f7a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_boston = datasets.load_boston()\n",
    "X = raw_boston.data\n",
    "y = raw_boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5653287",
   "metadata": {},
   "source": [
    "파이프라인을 사용하지 않은 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "246fcc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.51513779019758"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 트레이닝/테스트 데이터 분할\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state=7)\n",
    "\n",
    "# 표준화 스케일링\n",
    "std_scale = StandardScaler()\n",
    "X_tn_std = std_scale.fit_transform(X_tn)\n",
    "X_te_std = std_scale.transform(X_te)\n",
    "\n",
    "# 학습\n",
    "clf_linear = LinearRegression()\n",
    "clf_linear.fit(X_tn_std, y_tn)\n",
    "\n",
    "# 예측\n",
    "pred_linear = clf_linear.predict(X_te_std)\n",
    "\n",
    "# 평가\n",
    "mean_squared_error(y_te, pred_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee3934",
   "metadata": {},
   "source": [
    "파이프라인을 사용한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee044973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.51513779019758"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 트레이닝/테스트 데이터 분할\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state=7)\n",
    "\n",
    "# 표준화 스케일링\n",
    "# std_scale = StandardScaler()\n",
    "# X_tn_std = std_scale.fit_transform(X_tn)\n",
    "# X_te_std = std_scale.transform(X_te)\n",
    "# 학습\n",
    "# clf_linear = LinearRegression()\n",
    "# clf_linear.fit(X_tn_std, y_tn)\n",
    "# 예측\n",
    "# pred_linear = clf_linear.predict(X_te_std)\n",
    "\n",
    "# 파이프라인 => 표준화 스케일링 + 학습 객체 생성\n",
    "linear_pipeline = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linear_regression', LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 학습\n",
    "linear_pipeline.fit(X_tn, y_tn)\n",
    "\n",
    "# 예측\n",
    "pred_linear = linear_pipeline.predict(X_te)\n",
    "\n",
    "# 평가\n",
    "mean_squared_error(y_te, pred_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad07e6",
   "metadata": {},
   "source": [
    "그리드 서치(grid search)  \n",
    "그리드 서치는 머신러닝 과정에서 관심있는 매개 변수들을 대상으로 학습 가능하도록 만드는 방식을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac203d",
   "metadata": {},
   "source": [
    "K-최근접 이웃 알고리즘 사용시 1부터 10까지의 K값 후보중 가장 높은 성능을 보이는 K값 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ceb70aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "478be140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  1, best_accuracy:  0.000, accuracy:  0.921\n",
      "k:  2, best_accuracy:  0.921, accuracy:  0.947\n",
      "k:  3, best_accuracy:  0.947, accuracy:  0.974\n",
      "k:  4, best_accuracy:  0.974, accuracy:  0.974\n",
      "k:  5, best_accuracy:  0.974, accuracy:  0.974\n",
      "k:  6, best_accuracy:  0.974, accuracy:  0.974\n",
      "k:  7, best_accuracy:  0.974, accuracy:  0.974\n",
      "k:  8, best_accuracy:  0.974, accuracy:  0.974\n",
      "k:  9, best_accuracy:  0.974, accuracy:  0.974\n",
      "k: 10, best_accuracy:  0.974, accuracy:  0.974\n",
      "================================================================================\n",
      "k:  3, accuracy: 97.368%\n"
     ]
    }
   ],
   "source": [
    "# 붓꽃 데이터 불러오기\n",
    "raw_iris = datasets.load_iris()\n",
    "\n",
    "# 붓꽃 데이터에서 피처/타겟 데이터 읽기\n",
    "X = raw_iris.data\n",
    "y = raw_iris.target\n",
    "\n",
    "# 트레이닝/테스트 데이터 분할\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# 표준화 스케일링\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn)\n",
    "X_te_std = std_scale.transform(X_te)\n",
    "\n",
    "best_accuracy = 0 # 최고 정확도를 기억할 변수를 선언하고 0으로 초기화한다.\n",
    "# 1부터 10까지의 K값 후보중 가장 높은 성능을 보이는 K값을 정한다.\n",
    "for k in range(1, 11):\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=k) # kNN 객체를 생성한다.\n",
    "    clf_knn.fit(X_tn_std, y_tn) # 트레이닝 데이터로 학습한다.\n",
    "    knn_pred = clf_knn.predict(X_te_std) # 테스트 데이터로 예측한다.\n",
    "    accuracy = accuracy_score(y_te, knn_pred) # 테스트 데이터 실제값과 테스트 데이터 예측값으로 정확도를 계산한다.\n",
    "    # 가장 정확도가 높은 k를 계산한다.\n",
    "    print('k: {:2d}, best_accuracy: {:6.3f}, accuracy: {:6.3f}'.format(k, best_accuracy, accuracy))\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        final_k = k\n",
    "    # ===== if\n",
    "# ===== for\n",
    "print('=' * 80)\n",
    "print('k: {:2d}, accuracy: {:.3%}'.format(final_k, best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149aa8f",
   "metadata": {},
   "source": [
    "손실 함수(loss function)와 비용 함수(cost function)의 개념\n",
    "\n",
    "손실 함수는 머신러닝을 통해 생성한 모형이 실제값과 얼마나 차이가 나는지 즉, 손실 정도를 수치로 나타내는 함수로 모형 손실은 예측값과 실제값의 차이를 이용해 측정한다.\n",
    "\n",
    "손실 함수와 비슷하게 비용 함수라는 개념도 존재하는데 손실 함수는 각 데이터 포인트에 대해 예측값과 실제값의 차이를 나타내지만, 비용 함수는 데이터셋 전체를 대상으로 하는 손실을 의미한다. 엄밀하게 말하면 서로 다르다고 할 수도 있으나 실제로는 손실 함수와 비용 함수를 구분없이 사용하기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f514f81e",
   "metadata": {},
   "source": [
    "L1 손실 함수\n",
    "\n",
    "손실 함수에는 크게 L1 손실(L1 loss)과 L2 손실(L2 loss)이 존재한다. L1 손실은 다른말로 L1 비용(L1 cost)이라고도 부르며, 아래와 같이 표현한다.\n",
    "\n",
    "$$L1\\,Loss = \\sum |y_{true} - y_{predict}|$$\n",
    "\n",
    "$y_{true}$는 실제값을 의미하고, $y_{predict}$는 학습 모형을 이용해 예측한 값을 의미한다.\n",
    "\n",
    "즉, L1 손실은 실제값과 예측값의 차이에 절대값을 취한 것으로 실제값과 예측값의 차이를 줄이는 것이 학습 목적이다.  \n",
    "L1 손실과 관련된 비용 함수로 MAE(Mean Absolute Error)가 있다.\n",
    "\n",
    "$$MAE = \\frac{1}{n} \\sum_{i=1}^{n}{|y_i - \\hat y|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee60be46",
   "metadata": {},
   "source": [
    "L2 손실 함수\n",
    "\n",
    "L2 손실은 실제값과 예측값의 차이에 제곱을 취함으로써 구할 수 있다.\n",
    "\n",
    "$$L2\\,Loss = \\sum (y_{true} - y_{predict})^2$$\n",
    "\n",
    "L2 손실을 이용한 비용 함수에는 MSE(Mean Squared Error), RMSE(Root Mean Squared Error)가 존재한다.\n",
    "\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n}{(y_i - \\hat y)^2}, \\; RMSE = \\sqrt{MSE}$$\n",
    "\n",
    "MSE는 흔히 사용하는 비용 함수로 실제값과 예측값의 차이의 평균을 의미한다. RMSE는 MSE에 제곱근을 취한 형태이다. MSE를 구하는 과정에서 실제값과 예측값을 제곱하므로 MSE는 이상치(outlier)의 변화에 민감하다. 반면에 MAE나 RMSE는 이상치와 상관없이 안정된 값을 보여준다. 머신러닝 모형에서 이상치에 중점을 두고싶다면 MSE를 사용하고, 그렇치 않다면 MAE나 RMSE를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb8a4b0",
   "metadata": {},
   "source": [
    "엔트로피(entropy)\n",
    "\n",
    "엔트로피는 정보 이론에서 사용하는 개념으로 확률 변수의 불확실성 정도를 측정하기 위해 사용한다.\n",
    "\n",
    "■ 엔트로피\n",
    "\n",
    "$$Entropy(P) = - \\sum P(x)logP(x) = -E(logP(x))$$\n",
    "\n",
    "위 엔트로피 식은 $Entropy(P)$로 표기했지만 $H(P)$ 혹은 $H(X)$라고 쓰기도 하며 엔트로피는 의사결정 트리에서 주로 사용한다.\n",
    "\n",
    "■ 크로스 엔트로피\n",
    "\n",
    "$$CrossEntropy(P, Q) = - \\sum P(x)logQ(x) = -E_p(logQ(x))$$\n",
    "\n",
    "위 식은 크로스 엔트로피라고 하는데, 엔트로피는 하나의 분포를 대상으로 하는 반면, 크로스 엔트로피는 두 분포 $P(x)$, $Q(x)$를 대상으로 엔트로피를 측정해 두 분포간의 차이를 계산한다. 머신러닝에서 크로스 엔트로피를 사용할 대는 $P(x)$를 실제 모형의 분포, $Q(x)$ 추정 모형의 분포라고 설정한다.\n",
    "\n",
    "■ 쿨백-라이블러 발산(Kullback-Leibler Divergence)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_{KL}(P||Q) =& \\sum P(x)log \\frac{P(x)}{Q(x)} \\\\\n",
    "=& -\\sum P(x)logQ(x) + \\sum P(x)logP(x) \\\\\n",
    "=& -E_p(log \\frac{P(x)}{Q(x)})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "위 식은 쿨백-라이블러 발산(KLD)라는 개념이다. 크로스 엔트로피와 KLD는 머신러닝에서 자주 사용되는 손실 함수이다. KLD는 다른 말로 상대적 엔트로피(relative entropy)라고도 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e068fe45",
   "metadata": {},
   "source": [
    "모형 성능 평가\n",
    "\n",
    "모형 성능 평가에 필요한 개념  \n",
    "정답으로 분류되는 경우  \n",
    "데이터를 양성(positive)으로 예측했을 때, 실제값도 양성일 때 => True Positive(TP)  \n",
    "데이터를 음성(negative)으로 예측했을 때, 실제값도 음성일 때 => True Negative(TN)  \n",
    "오답으로 분류되는 경우  \n",
    "데이터를 양성(positive)으로 예측했을 때, 실제값이 음성일 때 => False Positive(FP)  \n",
    "데이터를 음성(negative)으로 예측했을 때, 실제값이 양성일 때 => False Negative(FN)  \n",
    "\n",
    "■ 정밀도(Precision): 양성으로 예측했을 때, 실제로 양성으로 나타나는 비율 => $\\frac{TP}{TP + FP}$  \n",
    "■ 재현율(Recall): 실제 양성에 해당하는 데이터가 양성으로 나타나는 비율 => $\\frac{TP}{TP + FN}$  \n",
    "■ 특이도(Specificity): 음성으로 예측했을 때, 실제로 음성으로 나타나는 비율 => $\\frac{TN}{FP + TN}$  \n",
    "■ False Positive Rate(FPR): 실제 음성에 해당하는 데이터가 양성으로 나타나는 비율 => $\\frac{FP}{FP + TN}$  \n",
    "■ 정확도(Accuracy): 전체 데이터 중 양성으로 분류되는 비율 => $\\frac{TP + TN}{TP + TN + FP + FN}$  \n",
    "■ 에러율(Error Rate): 전체 데이터 중 음성으로 분류되는 비율 => $\\frac{FP + FN}{TP + TN + FP + FN}$  \n",
    "■ Receiver Operating Characteristic(ROC) 커브: X축에 FPR을 놓고 Y축에 재현율의 값을 비교한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed1f343",
   "metadata": {},
   "source": [
    "머신러닝에서 우리가 풀어야 할 문제의 종류에 따라 성능 평가 방법이 달라지기도 한다.  \n",
    "\n",
    "분류 문제에서의 성능 평가  \n",
    "\n",
    "■ 정확도  \n",
    "정확도는 아래와 같은 식을 의미한다.\n",
    "\n",
    "$$accuracy = \\frac{1}{n} \\sum_{i = 1}^{n}{I(\\hat y_i = y_i)}$$\n",
    "\n",
    "위 식에서 $I$는 지시 함수(indicator function)를 의미한다. 지시 함수는 $\\hat y_i$과 $y_i$의 값이 동일하다면 1, 서로 다른 값을 가진다면 0을 가진다는 것을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb7d5dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 정확도를 측정하기 위해 accuracy_score 함수를 import 한다.\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = [0, 1, 2, 3] # 실제값\n",
    "y_pred = [0, 2, 1, 3] # 예측값\n",
    "# accuracy_score() 함수의 normalize 옵션의 기본값은 True가 적용되어 있어서 0부터 1사이의 값으로 나타난다.\n",
    "# 4개의 예측값과 실제값을 비교했을 때 두 개만 일치하므로 정확도는 2 / 4 = 0.5로 나타난다.\n",
    "print(accuracy_score(y_true, y_pred, normalize=True))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "# normalize=False로 지정한다면 0부터 1사이가 아니라 예측값과 실제값이 일치하는 빈도수를 출력한다.\n",
    "# 4개의 예측값과 실제값을 비교했을 때 2개의 값이 일치하므로 2가 출력된다.\n",
    "print(accuracy_score(y_true, y_pred, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c101aea",
   "metadata": {},
   "source": [
    "■ F1 score  \n",
    "F1 score는 정밀도(percision)와 재현율(recall)의 조화 평균값이라고 생각할 수 있다. F1 score 또한 0부터 1까지의 값을 가지며 1에 가까울수록 높은 성능을 나타낸다.  \n",
    "F1 score를 구하는 공식은 아래와 같다.\n",
    "\n",
    "$$F1 \\; score = 2 \\times \\frac{percision \\times recall}{percision + recall}$$\n",
    "\n",
    "■ 혼돈 행렬(Confusion Matrix)  \n",
    "혼돈 행렬을 확인하면 예측값과 실제값의 빈도를 행렬 형태로 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a1975ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 혼돈 행렬을 출력하기 위해 confusion_matrix 함수를 import 한다.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [2, 0, 2, 2, 0, 1] # 실제값\n",
    "y_pred = [0, 0, 2, 2, 0, 2] # 예측값\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e322fb1",
   "metadata": {},
   "source": [
    "결과를 확인하면 위에서부터 차례대로 클래스 0, 1, 2를 의미하고 행렬의 행은 실제값을 의미하고 열은 예측값을 의미한다. 즉, 주 대각 원소는 실제값과 예측값이 일치하는 경우를 의미하며, 대각 원소가 아닌 원소들은 실제값과 예측값이 차이가 나는 경우이다.\n",
    "\n",
    "■ 분류 리포트(classification report)  \n",
    "사이킷런에서 제공하는 분류 리포트를 사용하면 여러가지 성능 점수를 한눈에 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d52361c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class1       0.67      1.00      0.80         2\n",
      "      class2       0.00      0.00      0.00         1\n",
      "      class3       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.56      0.50      0.49         5\n",
      "weighted avg       0.67      0.60      0.59         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류 리포트를 출력하기 위해 classification_report 함수를 import 한다.\n",
    "from sklearn.metrics import classification_report\n",
    "y_true = [0, 1, 2, 2, 0] # 실제값\n",
    "y_pred = [0, 0, 2, 1, 0] # 예측값\n",
    "target_names = ['class1', 'class2', 'class3']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed16a2dd",
   "metadata": {},
   "source": [
    "accuracy : 전체 정확도  \n",
    "macro avg: 레벨별 가중치를 부여하지 않은 평균  \n",
    "weighted avg: support-weighted된 평균값, support는 실제값(y_true)의 클래스별 데이터 개수를 의미한다.\n",
    "\n",
    "회귀 문제에서의 성능 평가\n",
    "\n",
    "■ Mean Absolute Error  \n",
    "Mean Absolute Error(MAE)는 실제값과 예측값의 차이의 절대값의 평균을 의미하며 아래와 같은 식으로 표현된다.\n",
    "\n",
    "$$MAE = \\frac{1}{n} \\sum_{i=1}^{n}{|y_i - \\hat y|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04ccc3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# MAE를 계산하기 위해 mean_absolute_error 함수를 import 한다.\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "y_true = [3, -0.5, 2, 7] # 실제값\n",
    "y_pred = [2.5, 0.0, 2, 8] # 예측값\n",
    "print(mean_absolute_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd847af4",
   "metadata": {},
   "source": [
    "■ Mean Squared Error(MSE)  \n",
    "오차의 제곱합의 평균을 의미하며\n",
    "\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n}{(y_i - \\hat y)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5a93572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n"
     ]
    }
   ],
   "source": [
    "# MSE를 계산하기 위해 mean_squared_error 함수를 import 한다.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_true = [3, -0.5, 2, 7] # 실제값\n",
    "y_pred = [2.5, 0.0, 2, 8] # 예측값\n",
    "print(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd3bf1",
   "metadata": {},
   "source": [
    "■ r2 score  \n",
    "r2 score는 흔히 R 제곱값이라고 많이 부른다. 전체 모형에서 설명 가능한 분산의 비율을 나타낸다. R 제곱값은 0에서 1사이의 값을 가지며 1에 가까울수록 높은 성능을 의미하며 아래와 같은 식으로 표현된다.\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_{i=1}^{n}{(y_i - \\hat y)^2}}{\\sum_{i=1}^{n}{(y_i - \\bar y)^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e725485e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9486081370449679\n"
     ]
    }
   ],
   "source": [
    "# r2 score를 계산하기 위해 r2_score 함수를 import 한다.\n",
    "from sklearn.metrics import r2_score\n",
    "y_true = [3, -0.5, 2, 7] # 실제값\n",
    "y_pred = [2.5, 0.0, 2, 8] # 예측값\n",
    "print(r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a658ef",
   "metadata": {},
   "source": [
    "군집 문제에서의 성능 평가  \n",
    "군집 모형은 비지도 학습을 이용해 생성한 모형을 의미한다.\n",
    "\n",
    "■ 실루엣 스코어(silhouette score)  \n",
    "실루엣 스코어는 서로 다른 군집이 얼마나 잘 분리되어는지를 나타내는 지표이다. 이는 같은 군집의 데이터는 가까운 거리에 뭉쳐있고, 다른 군집의 데이터끼리는 멀리 떨어져 있을수록 높은 점수를 나타낸다.\n",
    "\n",
    "실루엣 스코어는 아래와 같은 식으로 표현하고 -1부터 1사이의 값을 가지면 스코어가 높을수록 좋은 성능을 의미한다.\n",
    "\n",
    "$$\\frac {b - a}{max(a, b)}$$\n",
    "\n",
    "위 식에서 a는 같은 클래스 내에서의 특정 데이터 포인트와 나머지 클래싀 내 다른 데이터 포인트 간의 평균 거리를 의미한다. b는 특정 데이터 포인트와 두 번째로 가까운 집단 내 포인트 간의 평균 거리를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "589fa063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5789497702625118\n"
     ]
    }
   ],
   "source": [
    "# 실루엣 스코어를 계산하기 위해 silhouette_score 함수를 import 한다.\n",
    "from sklearn.metrics import silhouette_score\n",
    "X = [[1, 2], [4, 5], [2, 1], [6, 7], [2, 3]]\n",
    "labels = [0, 1, 0, 1, 0]\n",
    "print(silhouette_score(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d53cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901b7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9192655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67384c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
