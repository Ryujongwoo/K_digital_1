{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9033da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a522c20",
   "metadata": {},
   "source": [
    "앙상블 학습(Ensemble Learning)\n",
    "\n",
    "지도 학습은 피쳐 데이터와 타겟 데이터를 이용해 전체 데이터를 분류하는 학습 방법이다.  \n",
    "지도 학습에 사용되는 데이터는 각 피쳐 데이터마다 타겟 변수가 올바르게 할당된 라벨링 데이터였고 이를 기반으로 학습 알고리즘을 생성하는 과정을 거쳤었다.\n",
    "\n",
    "앙상블 학습의 핵심 아이디어는 트레이닝 데이터를 기반으로 <u>분류 모형을 여러 개 만들고 서로 비교</u>하는 것이다.  \n",
    "앙상블 학습 과정에서 만든 개별 분류 모형을 분류기(classifier)라고 하고 <u>여러 개의 분류기를 결합</u>함으로써 <u>개별적인 분류기보다 성능이 뛰어난 최종 분류기를 만드는 것</u>이 앙상블 학습의 목적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff22cbf",
   "metadata": {},
   "source": [
    "보팅(Voting)  \n",
    "여러 개의 분류 모형의 결과를 대상으로 <u>투표</u>를 통해서 최종 클래스 레이블을 정하는 방법이다.\n",
    "\n",
    "분류기가 10개 있다고 했을 때, 특정 데이터에 대해 7개의 분류기는 클래스 1이라고 예측하고, 나머지 3개의 분류 모형은 클래스가 2라고 예측했다고 했을 때 클래스 1이 가장 높은 득표수를 보이므로 최종적으로 클래스 1로 예측하는 것이다. 이를 다수결 투표(pluarlity voting)라고 하는데 이와 비슷한 방법으로 다수결이 아닌 절반 이상의 분류기의 표를 얻어야 하는 과반수 투표(majority voting) 방식이 있다.\n",
    "\n",
    "개별 분류기는 지도 학습 방법 중 로지스틱 회귀, 서포트 벡터 머신, 의사 결정 트리 등 여러 가지 알고리즘 사용해서 다양한 분류 모형을 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba8182",
   "metadata": {},
   "source": [
    "보팅 알고리즘을 활용해 붓꽃 데이터를 분류하는 앙상블 모형을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6619d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "from sklearn import datasets # 붓꽃 데이터를 사용하기 위해 datasets를 import 한다.\n",
    "raw_iris = datasets.load_iris() # 붓꽃 데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eac5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처/타겟 데이터 지정\n",
    "X = raw_iris.data # 붓꽃 피쳐 데이터를 저장한다.\n",
    "y = raw_iris.target # 붗꽃 타겟 데이터를 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e8da710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이닝/테스트 데이터 분할\n",
    "from sklearn.model_selection import train_test_split # 트레이닝/테스트 데이터 분할을 위해 import 한다.\n",
    "# train_test_split() 함수의 인수로 피쳐와 타겟 데이터를 넘겨 트레이닝 데이터와 테스트 데이터로 나눈다.\n",
    "# 공부할 때는 매번 실행할 때 마다 결과가 달라지지 않도록 random_state를 지정하면 좋다.\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "680a4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화\n",
    "from sklearn.preprocessing import StandardScaler # 데이터 표준화를 위해 import 한다.\n",
    "std_scale = StandardScaler() # 표준화 스케일러 객체를 만든다.\n",
    "# 표준화는 트레이닝 데이터를 기반으로 실행하므로 트레이닝 피쳐 데이터 X_tn을 표준화 스케일러에 적합시킨다.\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn) # 트레이닝 피쳐 데이터 X_tn을 표준화 한다.\n",
    "X_te_std = std_scale.transform(X_te) # 테스트 피쳐 데이터 X_te를 표준화 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf68979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(multi_class='multinomial',\n",
       "                                                 random_state=1)),\n",
       "                             ('svm', SVC(kernel='linear', random_state=1)),\n",
       "                             ('gnb', GaussianNB())],\n",
       "                 weights=[1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 보팅 학습\n",
    "from sklearn.linear_model import LogisticRegression # 로지스틱 회귀 알고리즘을 사용하기 위해 import 한다.\n",
    "from sklearn.svm import SVC # 서포트 벡터 머신 알고리즘을 사용하기 위해 import 한다.\n",
    "from sklearn.naive_bayes import GaussianNB # 가우시안 나이브 베이즈 알고리즘을 사용하기 위해 import 한다.\n",
    "# 분류 문제이므로 VotingClassifier를 사용하지만 회귀 문제라면 VotingRegressor를 사용한다.\n",
    "from sklearn.ensemble import VotingClassifier # 보팅 알고리즘을 사용하기 위해 import 한다.\n",
    "\n",
    "# 사이킷런의 LogisticRegression의 multi_class 옵션은 'ovr'일 경우 binary classification, 'multinomial'일 경우\n",
    "# multi classification, 'auto'일 경우 타겟값 유형을 자동으로 해석해서 'ovr' 또는 'multinomial'을 적용한다.\n",
    "clf1 = LogisticRegression(multi_class='multinomial', random_state=1) # 로지스틱 회귀 분석 객체를 만든다.\n",
    "clf2 = SVC(kernel='linear', random_state=1) # 서포트 벡터 머신 객체를 만든다.\n",
    "clf3 = GaussianNB() # 가우시안 나이브 베이즈 객체를 만든다.\n",
    "\n",
    "# 앞서 만든 세 가지 모형을 이용해 보팅 모형을 만든다.\n",
    "# estimators 옵션으로 앞서 만든 세 가지 모형을 지정한다.\n",
    "# voting 옵션은 hard 또는 soft를 설정하는데 hard를 사용하면 투표 결과로 과반수가 넘는 라벨이 정해지고, soft로 \n",
    "# 설정하면 득표수가 가장 높은 라벨로 정해진다.\n",
    "# weights 옵션으로 앞서 만든 세 가지 모형의 가중치를 지정한다.\n",
    "clf_voting = VotingClassifier(estimators=[('lr', clf1), ('svm', clf2), ('gnb', clf3)], voting='hard', \n",
    "                              weights=[1, 1, 1])\n",
    "# 표준화된 피쳐 데이터 X_tn_std와 트레이닝 타겟 데이터 y_tn을 넣어서 앙상블(보팅) 알고리즘을 학습시킨다.\n",
    "clf_voting.fit(X_tn_std, y_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "301e74e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 예측\n",
    "pred_voting = clf_voting.predict(X_te_std) # 표준화된 테스트 데이터 X_te_std로 예측한다.\n",
    "print(pred_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8593c793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# 정확도 평가\n",
    "from sklearn.metrics import accuracy_score # 모형 정확도를 평가하기 위해 import 한다.\n",
    "# accuracy_score() 함수의 인수로 실제 타겟 데이터와 예측된 데이터를 넘겨 정확도를 평가한다.\n",
    "accuracy = accuracy_score(y_te, pred_voting)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b271994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "# 혼돈 행렬 확인\n",
    "from sklearn.metrics import confusion_matrix # 혼돈 행렬을 만들기 위해 import 한다.\n",
    "# confusion_matrix() 함수에 실제 타겟 데이터와 예측된 데이터를 넘겨 혼돈 행렬을 만든다.\n",
    "conf_matrix = confusion_matrix(y_te, pred_voting)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63248ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류 리포트 확인\n",
    "from sklearn.metrics import classification_report # 분류 리포트를 출력하기 위해 import 한다.\n",
    "# classification_report() 함수에 실제 타겟 데이터와 예측된 데이터를 넘겨 분류 리포트를 만든다.\n",
    "class_report = classification_report(y_te, pred_voting)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f60fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
