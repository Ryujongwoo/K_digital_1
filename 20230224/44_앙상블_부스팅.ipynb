{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a32e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330e1f6",
   "metadata": {},
   "source": [
    "부스팅(Boosting)  \n",
    "초기에는 모든 데이터 포인트에 동일한 가중치를 할당하고 점차 학습이 진행되면서 올바르게 분류된 데이터 포인트의 가중치는 감소시키는 반면에 잘못 분류된 데이터 포인트의 가중치는 증가시킨다.  \n",
    "결과적으로 학습이 진행되면서 학습는 분류하기 어려운 데이터에 집중하게 되고 이전 단계에서 만들어진 학습기는 다음 단계에서 사용할 트레이닝 셋의 가중치를 반영하는 데 사용하므로 부스팅인 배깅과는 달리 이전 분류기의 영향을 받는다.\n",
    "\n",
    "배깅에서는 각 데이터 포인트가 추출될 확률이 모두 동일했지만, 부스팅에서는 각 데이터 포인트에 할당된 가중치에 비례해서 추출된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b3a32",
   "metadata": {},
   "source": [
    "에이다 부스트(Adaboost)  \n",
    "부스팅은 약한 학습기 여러 개를 모아 하나의 강한 학습기를 만드는 방법으로 개별적으로는 약한 학습 모형이지만, 이와 같은 모형을 다수 생성하고 부스팅을 적용함으로써 강한 학습기가 만들어진다.  \n",
    "\n",
    "보팅이나 배깅은 모델이 병려적으로 수행된다. 10개의 모델이 이다면 10개의 모델을 동시에 학습시킬 수 있다는 뜻이다. 이에 반해 부스팅은 여러 약한 학습기가 순차적으로 적용된다. 그 이유는, 약한 학습 모형의 학습 이후 판별하지 못한 데이터 포인트에 대해서 가중치를 부여하기 때문이다.  \n",
    "\n",
    "에이다 부스트의 핵심 아이디어는 분류하기 어려운 트레이닝 데이터에 가중치를 더 높이는 것이다. 즉, 이전에 잘못 분류된 트레이닝 데이터 포인트는 가중치가 증가해 오차율이 높아진다. 다음 약한 학습기는 이전에 증가한 오차를 낮추는 방향으로 학습하게 된다.  \n",
    "에이다 부스트는 일반적인 부스팅과는 다르게 약한 학습기를 훈련할 때 훈련 데이터셋 전체를 사용한다. 훈련 샘프은 반복할 때마다 가중치가 부여되며 이 앙상블은 이전 학습기의 실수한 부분을 학습하는 강력한 분류기를 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb531b",
   "metadata": {},
   "source": [
    "에이다 부스트 알고리즘을 활용해 암 여부를 예측하는 모형을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d407b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "from sklearn import datasets # 위스콘신 암 데이터를 사용하기 위해 import 한다.\n",
    "raw_cancer = datasets.load_breast_cancer() # 위스콘신 암 데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3775aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피쳐/타겟 데이터 지정\n",
    "X = raw_cancer.data # 위스콘신 암 피쳐 데이터를 저장한다.\n",
    "y = raw_cancer.target # 위스콘신 암 타겟 데이터를 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3724b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30) (143, 30)\n"
     ]
    }
   ],
   "source": [
    "# 트레이닝/테스트 데이터 분할\n",
    "from sklearn.model_selection import train_test_split # 트레이닝/테스트 데이터 분할을 위해 import 한다.\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state=0) # 트레이닝 데이터와 테스트 데이터로 분할한다.\n",
    "print(X_tn.shape, X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a16a7a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화\n",
    "from sklearn.preprocessing import StandardScaler # 데이터 표준화를 위해 import 한다.\n",
    "std_scale = StandardScaler() # 표준화 스케일러 객체를 만든다.\n",
    "# 표준화는 트레이닝 데이터를 기반으로 실행하므로 트레이닝 피쳐 데이터 X_tn을 표준화 스케일러에 적합시킨다.\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn) # 트레이닝 피쳐 데이터 X_tn을 표준화 한다.\n",
    "X_te_std = std_scale.transform(X_te) # 테스트 피쳐 데이터 X_te를 표준화 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8129e770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 학습\n",
    "# 분류 문제이므로 AdaBoostClassifier를 사용하지만 회귀 문제라면 AdaBoostRegressor를 사용한다.\n",
    "from sklearn.ensemble import AdaBoostClassifier # 에이다 부스트 알고리즘을 사용하기 위해 import 한다.\n",
    "clf_ada = AdaBoostClassifier(random_state=0) # 에이다 부스트 모델 객체를 만든다.\n",
    "# 표준화된 피쳐 데이터 X_tn_std와 트레이닝 타겟 데이터 y_tn을 넣어서 랜덤 포레스트 알고리즘을 학습시킨다.\n",
    "clf_ada.fit(X_tn_std, y_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39e12d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 예측\n",
    "pred_ada = clf_ada.predict(X_te_std) # 표준화된 테스트 데이터 X_te_std로 예측한다.\n",
    "print(pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3bd455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "# 정확도 평가\n",
    "from sklearn.metrics import accuracy_score # 모형 정확도를 평가하기 위해 import 한다.\n",
    "# accuracy_score() 함수의 인수로 실제 타겟 데이터와 예측된 데이터를 넘겨 정확도를 평가한다.\n",
    "accuracy = accuracy_score(y_te, pred_ada)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60b7077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52  1]\n",
      " [ 2 88]]\n"
     ]
    }
   ],
   "source": [
    "# 혼돈 행렬 확인\n",
    "from sklearn.metrics import confusion_matrix # 혼돈 행렬을 만들기 위해 import 한다.\n",
    "# confusion_matrix() 함수에 실제 타겟 데이터와 예측된 데이터를 넘겨 혼돈 행렬을 만든다.\n",
    "conf_matrix = confusion_matrix(y_te, pred_ada)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d32a01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        53\n",
      "           1       0.99      0.98      0.98        90\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류 리포트 확인\n",
    "from sklearn.metrics import classification_report # 분류 리포트를 출력하기 위해 import 한다.\n",
    "# classification_report() 함수에 실제 타겟 데이터와 예측된 데이터를 넘겨 분류 리포트를 만든다.\n",
    "class_report = classification_report(y_te, pred_ada)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61cb591",
   "metadata": {},
   "source": [
    "그래디언트 부스팅(Graient boosting)  \n",
    "그래디언트 부스팅은 부스팅의 한 종류로 그래디언트를 이용해 부스팅을 하는 방법이다. 그래디언트 부스팅은 비용 함수를 최적화 시킴으로써 학습 능력을 향상시키는 알고리즘이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac86ce8a",
   "metadata": {},
   "source": [
    "그래디언트 부스팅 알고리즘을 활용해 암 여부를 예측하는 모형을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc37610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.01, max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 학습\n",
    "# 분류 문제이므로 GradientBoostingClassifier를 사용하지만 회귀 문제라면 GradientBoostingRegressor를 사용한다.\n",
    "from sklearn.ensemble import GradientBoostingClassifier # 그래디언트 부스트 알고리즘을 사용하기 위해 import 한다.\n",
    "# 그래디언트 부스트 모델 객체를 만든다.\n",
    "clf_gbt = GradientBoostingClassifier(max_depth=2, learning_rate=0.01, random_state=0)\n",
    "# 표준화된 피쳐 데이터 X_tn_std와 트레이닝 타겟 데이터 y_tn을 넣어서 랜덤 포레스트 알고리즘을 학습시킨다.\n",
    "clf_gbt.fit(X_tn_std, y_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93df741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 예측\n",
    "pred_gboost = clf_gbt.predict(X_te_std) # 표준화된 테스트 데이터 X_te_std로 예측한다.\n",
    "print(pred_gboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d947d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "# 정확도 평가\n",
    "from sklearn.metrics import accuracy_score # 모형 정확도를 평가하기 위해 import 한다.\n",
    "# accuracy_score() 함수의 인수로 실제 타겟 데이터와 예측된 데이터를 넘겨 정확도를 평가한다.\n",
    "accuracy = accuracy_score(y_te, pred_gboost)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54e215ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49  4]\n",
      " [ 1 89]]\n"
     ]
    }
   ],
   "source": [
    "# 혼돈 행렬 확인\n",
    "from sklearn.metrics import confusion_matrix # 혼돈 행렬을 만들기 위해 import 한다.\n",
    "# confusion_matrix() 함수에 실제 타겟 데이터와 예측된 데이터를 넘겨 혼돈 행렬을 만든다.\n",
    "conf_matrix = confusion_matrix(y_te, pred_gboost)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82eec9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        53\n",
      "           1       0.96      0.99      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류 리포트 확인\n",
    "from sklearn.metrics import classification_report # 분류 리포트를 출력하기 위해 import 한다.\n",
    "# classification_report() 함수에 실제 타겟 데이터와 예측된 데이터를 넘겨 분류 리포트를 만든다.\n",
    "class_report = classification_report(y_te, pred_gboost)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbf787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
